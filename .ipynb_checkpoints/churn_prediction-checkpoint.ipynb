{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school_id</th>\n",
       "      <th>emiscode</th>\n",
       "      <th>school_name</th>\n",
       "      <th>district</th>\n",
       "      <th>tehsil</th>\n",
       "      <th>markaz</th>\n",
       "      <th>moza</th>\n",
       "      <th>permanent_address</th>\n",
       "      <th>street_name</th>\n",
       "      <th>uc_name</th>\n",
       "      <th>...</th>\n",
       "      <th>total_computer_training_students</th>\n",
       "      <th>internet</th>\n",
       "      <th>ece_room</th>\n",
       "      <th>ece_room_under_construction</th>\n",
       "      <th>ece_equipments</th>\n",
       "      <th>ece_trained_teachers</th>\n",
       "      <th>care_giver</th>\n",
       "      <th>enrollment</th>\n",
       "      <th>Teachers</th>\n",
       "      <th>NonTeachers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>21007.0</td>\n",
       "      <td>34120175</td>\n",
       "      <td>GPS NO. 7 GAKHAR</td>\n",
       "      <td>GUJRANWALA</td>\n",
       "      <td>WAZIRABAD</td>\n",
       "      <td>GHAKHAR 1 - MALE</td>\n",
       "      <td>Ghakhar</td>\n",
       "      <td>GPS no 7 ghakhar bangla abadi</td>\n",
       "      <td>Ghakhar</td>\n",
       "      <td>Ghakhar 2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>20997.0</td>\n",
       "      <td>34120163</td>\n",
       "      <td>GES AZIZ CHAK</td>\n",
       "      <td>GUJRANWALA</td>\n",
       "      <td>WAZIRABAD</td>\n",
       "      <td>WAZIRABAD SADAR 1 - MALE</td>\n",
       "      <td>Aziz chak</td>\n",
       "      <td>Aziz chak Teh Wazirabad GRW</td>\n",
       "      <td>Aziz chak</td>\n",
       "      <td>Ghakka mitter</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>385.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>20985.0</td>\n",
       "      <td>34120146</td>\n",
       "      <td>GPS HARRIAN WALA KHURID</td>\n",
       "      <td>GUJRANWALA</td>\n",
       "      <td>WAZIRABAD</td>\n",
       "      <td>GHAKHAR 1 - MALE</td>\n",
       "      <td>Hairanwsla Khurd</td>\n",
       "      <td>vil hairanwala khurd the wzd dist grw</td>\n",
       "      <td>Hairanwala Khurd</td>\n",
       "      <td>Joura</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>21283.0</td>\n",
       "      <td>34120537</td>\n",
       "      <td>GGPS RUKH SINGH PURA</td>\n",
       "      <td>GUJRANWALA</td>\n",
       "      <td>WAZIRABAD</td>\n",
       "      <td>RASOOL NAGAR 2 - FEMALE</td>\n",
       "      <td>Rukh Sing Pura</td>\n",
       "      <td>Rukh sing Pura, Tehsil Wazirabad, Distt Gujran...</td>\n",
       "      <td>Rukh Sing pura</td>\n",
       "      <td>Rasool Nagar</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>20963.0</td>\n",
       "      <td>34120105</td>\n",
       "      <td>GPS SOHDRA NO.1</td>\n",
       "      <td>GUJRANWALA</td>\n",
       "      <td>WAZIRABAD</td>\n",
       "      <td>WAZIRABAD SADAR 1 - MALE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GPS No.1 Sohddra Main Bazar Sohdra</td>\n",
       "      <td>Sohdra</td>\n",
       "      <td>Sohdra</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>306.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 108 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   school_id  emiscode              school_name    district     tehsil  \\\n",
       "0    21007.0  34120175         GPS NO. 7 GAKHAR  GUJRANWALA  WAZIRABAD   \n",
       "1    20997.0  34120163            GES AZIZ CHAK  GUJRANWALA  WAZIRABAD   \n",
       "2    20985.0  34120146  GPS HARRIAN WALA KHURID  GUJRANWALA  WAZIRABAD   \n",
       "3    21283.0  34120537     GGPS RUKH SINGH PURA  GUJRANWALA  WAZIRABAD   \n",
       "4    20963.0  34120105          GPS SOHDRA NO.1  GUJRANWALA  WAZIRABAD   \n",
       "\n",
       "                     markaz              moza  \\\n",
       "0          GHAKHAR 1 - MALE           Ghakhar   \n",
       "1  WAZIRABAD SADAR 1 - MALE         Aziz chak   \n",
       "2          GHAKHAR 1 - MALE  Hairanwsla Khurd   \n",
       "3   RASOOL NAGAR 2 - FEMALE    Rukh Sing Pura   \n",
       "4  WAZIRABAD SADAR 1 - MALE               NaN   \n",
       "\n",
       "                                   permanent_address       street_name  \\\n",
       "0                      GPS no 7 ghakhar bangla abadi           Ghakhar   \n",
       "1                        Aziz chak Teh Wazirabad GRW         Aziz chak   \n",
       "2              vil hairanwala khurd the wzd dist grw  Hairanwala Khurd   \n",
       "3  Rukh sing Pura, Tehsil Wazirabad, Distt Gujran...    Rukh Sing pura   \n",
       "4                 GPS No.1 Sohddra Main Bazar Sohdra            Sohdra   \n",
       "\n",
       "         uc_name  ...  total_computer_training_students  internet  ece_room  \\\n",
       "0      Ghakhar 2  ...                               NaN       0.0       1.0   \n",
       "1  Ghakka mitter  ...                               NaN       0.0       0.0   \n",
       "2          Joura  ...                               NaN       1.0       1.0   \n",
       "3   Rasool Nagar  ...                               NaN       1.0       0.0   \n",
       "4         Sohdra  ...                               NaN       1.0       1.0   \n",
       "\n",
       "  ece_room_under_construction ece_equipments  ece_trained_teachers care_giver  \\\n",
       "0                         0.0            0.0                   1.0        1.0   \n",
       "1                         0.0            0.0                   0.0        0.0   \n",
       "2                         0.0            1.0                   1.0        0.0   \n",
       "3                         0.0            0.0                   0.0        0.0   \n",
       "4                         0.0            1.0                   1.0        1.0   \n",
       "\n",
       "  enrollment Teachers NonTeachers  \n",
       "0      197.0      4.0         NaN  \n",
       "1      385.0     14.0         1.0  \n",
       "2       84.0      4.0         NaN  \n",
       "3       90.0      4.0         NaN  \n",
       "4      306.0      8.0         NaN  \n",
       "\n",
       "[5 rows x 108 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Churn_Modelling.csv')\n",
    "data = pd.read_csv(r\"C:\\Users\\sunny\\Desktop\\Census_Oct_2018.csv\")\n",
    "\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns = ['Geography', 'Gender'], drop_first= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>645</td>\n",
       "      <td>44</td>\n",
       "      <td>8</td>\n",
       "      <td>113755.78</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>149756.71</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>822</td>\n",
       "      <td>50</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10062.80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>376</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>115046.74</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>119346.88</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>501</td>\n",
       "      <td>44</td>\n",
       "      <td>4</td>\n",
       "      <td>142051.07</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>74940.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>684</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>134603.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>71725.73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>528</td>\n",
       "      <td>31</td>\n",
       "      <td>6</td>\n",
       "      <td>102016.72</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>80181.12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>497</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>76390.01</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>476</td>\n",
       "      <td>34</td>\n",
       "      <td>10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>26260.98</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>549</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>190857.79</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>635</td>\n",
       "      <td>35</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>65951.65</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>616</td>\n",
       "      <td>45</td>\n",
       "      <td>3</td>\n",
       "      <td>143129.41</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>64327.26</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>653</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>132602.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5097.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>549</td>\n",
       "      <td>24</td>\n",
       "      <td>9</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14406.41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>587</td>\n",
       "      <td>45</td>\n",
       "      <td>6</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>158684.81</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>726</td>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>54724.03</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>732</td>\n",
       "      <td>41</td>\n",
       "      <td>8</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>170886.17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>636</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>138555.46</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>510</td>\n",
       "      <td>38</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>118913.53</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>669</td>\n",
       "      <td>46</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8487.75</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>846</td>\n",
       "      <td>38</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>187616.16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>577</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>124508.29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>756</td>\n",
       "      <td>36</td>\n",
       "      <td>2</td>\n",
       "      <td>136815.64</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>170041.95</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>571</td>\n",
       "      <td>44</td>\n",
       "      <td>9</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38433.35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>574</td>\n",
       "      <td>43</td>\n",
       "      <td>3</td>\n",
       "      <td>141349.43</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>100187.43</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>411</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>59697.17</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>53483.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9970</th>\n",
       "      <td>518</td>\n",
       "      <td>42</td>\n",
       "      <td>7</td>\n",
       "      <td>151027.05</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>119377.36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9971</th>\n",
       "      <td>833</td>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "      <td>144751.81</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>166472.81</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9972</th>\n",
       "      <td>758</td>\n",
       "      <td>26</td>\n",
       "      <td>4</td>\n",
       "      <td>155739.76</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>171552.02</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9973</th>\n",
       "      <td>611</td>\n",
       "      <td>27</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>157474.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9974</th>\n",
       "      <td>583</td>\n",
       "      <td>33</td>\n",
       "      <td>7</td>\n",
       "      <td>122531.86</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13549.24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9975</th>\n",
       "      <td>610</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>113957.01</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>196526.55</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9976</th>\n",
       "      <td>637</td>\n",
       "      <td>33</td>\n",
       "      <td>7</td>\n",
       "      <td>103377.81</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>84419.78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9977</th>\n",
       "      <td>683</td>\n",
       "      <td>32</td>\n",
       "      <td>9</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>24991.92</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9978</th>\n",
       "      <td>774</td>\n",
       "      <td>40</td>\n",
       "      <td>9</td>\n",
       "      <td>93017.47</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>191608.97</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9979</th>\n",
       "      <td>677</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>90022.85</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2988.28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9980</th>\n",
       "      <td>741</td>\n",
       "      <td>35</td>\n",
       "      <td>6</td>\n",
       "      <td>74371.49</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>99595.67</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9981</th>\n",
       "      <td>498</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>152039.70</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>53445.17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9982</th>\n",
       "      <td>655</td>\n",
       "      <td>46</td>\n",
       "      <td>7</td>\n",
       "      <td>137145.12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>115146.40</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9983</th>\n",
       "      <td>613</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>151325.24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9984</th>\n",
       "      <td>602</td>\n",
       "      <td>35</td>\n",
       "      <td>7</td>\n",
       "      <td>90602.42</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>51695.41</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9985</th>\n",
       "      <td>659</td>\n",
       "      <td>36</td>\n",
       "      <td>6</td>\n",
       "      <td>123841.49</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96833.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9986</th>\n",
       "      <td>673</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>183579.54</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>34047.54</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9987</th>\n",
       "      <td>606</td>\n",
       "      <td>30</td>\n",
       "      <td>8</td>\n",
       "      <td>180307.73</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1914.41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9988</th>\n",
       "      <td>775</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>49337.84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9989</th>\n",
       "      <td>841</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>179436.60</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9990</th>\n",
       "      <td>714</td>\n",
       "      <td>33</td>\n",
       "      <td>3</td>\n",
       "      <td>35016.60</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53667.08</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9991</th>\n",
       "      <td>597</td>\n",
       "      <td>53</td>\n",
       "      <td>4</td>\n",
       "      <td>88381.21</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>69384.71</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9992</th>\n",
       "      <td>726</td>\n",
       "      <td>36</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>195192.40</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9993</th>\n",
       "      <td>644</td>\n",
       "      <td>28</td>\n",
       "      <td>7</td>\n",
       "      <td>155060.41</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>29179.52</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9994</th>\n",
       "      <td>800</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>167773.55</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>771</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>516</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>709</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>772</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>792</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "0             619   42       2       0.00              1          1   \n",
       "1             608   41       1   83807.86              1          0   \n",
       "2             502   42       8  159660.80              3          1   \n",
       "3             699   39       1       0.00              2          0   \n",
       "4             850   43       2  125510.82              1          1   \n",
       "...           ...  ...     ...        ...            ...        ...   \n",
       "9995          771   39       5       0.00              2          1   \n",
       "9996          516   35      10   57369.61              1          1   \n",
       "9997          709   36       7       0.00              1          0   \n",
       "9998          772   42       3   75075.31              2          1   \n",
       "9999          792   28       4  130142.79              1          1   \n",
       "\n",
       "      IsActiveMember  EstimatedSalary  Geography_Germany  Geography_Spain  \\\n",
       "0                  1        101348.88                  0                0   \n",
       "1                  1        112542.58                  0                1   \n",
       "2                  0        113931.57                  0                0   \n",
       "3                  0         93826.63                  0                0   \n",
       "4                  1         79084.10                  0                1   \n",
       "...              ...              ...                ...              ...   \n",
       "9995               0         96270.64                  0                0   \n",
       "9996               1        101699.77                  0                0   \n",
       "9997               1         42085.58                  0                0   \n",
       "9998               0         92888.52                  1                0   \n",
       "9999               0         38190.78                  0                0   \n",
       "\n",
       "      Gender_Male  \n",
       "0               0  \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  \n",
       "4               0  \n",
       "...           ...  \n",
       "9995            1  \n",
       "9996            1  \n",
       "9997            0  \n",
       "9998            1  \n",
       "9999            0  \n",
       "\n",
       "[10000 rows x 11 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop(columns = ['Exited', 'RowNumber', 'CustomerId','Surname'])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       0\n",
       "2       0\n",
       "3       0\n",
       "4       0\n",
       "       ..\n",
       "9995    1\n",
       "9996    1\n",
       "9997    0\n",
       "9998    1\n",
       "9999    0\n",
       "Name: Gender_Male, Length: 10000, dtype: uint8"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df.iloc[:,-1]\n",
    "y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.16958176, -0.46460796,  0.00666099, ..., -0.5698444 ,\n",
       "         1.74309049, -1.09168714],\n",
       "       [-2.30455945,  0.30102557, -1.37744033, ...,  1.75486502,\n",
       "        -0.57369368,  0.91601335],\n",
       "       [-1.19119591, -0.94312892, -1.031415  , ..., -0.5698444 ,\n",
       "        -0.57369368, -1.09168714],\n",
       "       ...,\n",
       "       [ 0.9015152 , -0.36890377,  0.00666099, ..., -0.5698444 ,\n",
       "        -0.57369368,  0.91601335],\n",
       "       [-0.62420521, -0.08179119,  1.39076231, ..., -0.5698444 ,\n",
       "         1.74309049, -1.09168714],\n",
       "       [-0.28401079,  0.87525072, -1.37744033, ...,  1.75486502,\n",
       "        -0.57369368, -1.09168714]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\sunny\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\sunny\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\sunny\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\sunny\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\sunny\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\sunny\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\sunny\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\sunny\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\sunny\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\sunny\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\sunny\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\sunny\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# Part 2 - Now let's make the ANN!\n",
    "\n",
    "# Importing the Keras libraries and packages\n",
    "import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LeakyReLU,PReLU,ELU\n",
    "from tensorflow.keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising the ANN\n",
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the input layer and the first hidden layer\n",
    "classifier.add(Dense(units = 6, kernel_initializer = 'he_uniform',activation='relu',input_dim = 11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the second hidden layer\n",
    "classifier.add(Dense(units = 6, kernel_initializer = 'he_uniform',activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the output layer\n",
    "classifier.add(Dense(units = 1, kernel_initializer = 'glorot_uniform', activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the ANN\n",
    "classifier.compile(optimizer = 'Adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0902 11:13:52.140400 18988 training.py:617] The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "W0902 11:13:52.283546 18988 deprecation.py:323] From C:\\Users\\sunny\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5359 samples, validate on 2641 samples\n",
      "Epoch 1/100\n",
      "5359/5359 [==============================] - 2s 385us/sample - loss: 0.5672 - accuracy: 0.6822 - val_loss: 0.2911 - val_accuracy: 0.9099\n",
      "Epoch 2/100\n",
      "5359/5359 [==============================] - 2s 321us/sample - loss: 0.0746 - accuracy: 0.9890 - val_loss: 0.0128 - val_accuracy: 1.0000\n",
      "Epoch 3/100\n",
      "5359/5359 [==============================] - 1s 196us/sample - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 4/100\n",
      "5359/5359 [==============================] - 1s 168us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 5/100\n",
      "5359/5359 [==============================] - 1s 191us/sample - loss: 9.7894e-04 - accuracy: 1.0000 - val_loss: 7.5311e-04 - val_accuracy: 1.0000\n",
      "Epoch 6/100\n",
      "5359/5359 [==============================] - 1s 173us/sample - loss: 5.4804e-04 - accuracy: 1.0000 - val_loss: 4.4384e-04 - val_accuracy: 1.0000\n",
      "Epoch 7/100\n",
      "5359/5359 [==============================] - 1s 178us/sample - loss: 3.3423e-04 - accuracy: 1.0000 - val_loss: 2.7879e-04 - val_accuracy: 1.0000\n",
      "Epoch 8/100\n",
      "5359/5359 [==============================] - 1s 174us/sample - loss: 2.1473e-04 - accuracy: 1.0000 - val_loss: 1.8228e-04 - val_accuracy: 1.0000\n",
      "Epoch 9/100\n",
      "5359/5359 [==============================] - 1s 184us/sample - loss: 1.4300e-04 - accuracy: 1.0000 - val_loss: 1.2287e-04 - val_accuracy: 1.0000\n",
      "Epoch 10/100\n",
      "5359/5359 [==============================] - 1s 208us/sample - loss: 9.7722e-05 - accuracy: 1.0000 - val_loss: 8.4732e-05 - val_accuracy: 1.0000\n",
      "Epoch 11/100\n",
      "5359/5359 [==============================] - 1s 187us/sample - loss: 6.7999e-05 - accuracy: 1.0000 - val_loss: 5.9272e-05 - val_accuracy: 1.0000\n",
      "Epoch 12/100\n",
      "5359/5359 [==============================] - 1s 189us/sample - loss: 4.7937e-05 - accuracy: 1.0000 - val_loss: 4.1997e-05 - val_accuracy: 1.0000\n",
      "Epoch 13/100\n",
      "5359/5359 [==============================] - 1s 204us/sample - loss: 3.4149e-05 - accuracy: 1.0000 - val_loss: 2.9956e-05 - val_accuracy: 1.0000\n",
      "Epoch 14/100\n",
      "5359/5359 [==============================] - 1s 182us/sample - loss: 2.4516e-05 - accuracy: 1.0000 - val_loss: 2.1522e-05 - val_accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "5359/5359 [==============================] - 1s 266us/sample - loss: 1.7702e-05 - accuracy: 1.0000 - val_loss: 1.5553e-05 - val_accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "5359/5359 [==============================] - 1s 215us/sample - loss: 1.2836e-05 - accuracy: 1.0000 - val_loss: 1.1277e-05 - val_accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "5359/5359 [==============================] - 1s 221us/sample - loss: 9.3374e-06 - accuracy: 1.0000 - val_loss: 8.1977e-06 - val_accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "5359/5359 [==============================] - 1s 213us/sample - loss: 6.8087e-06 - accuracy: 1.0000 - val_loss: 5.9788e-06 - val_accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "5359/5359 [==============================] - 1s 207us/sample - loss: 4.9691e-06 - accuracy: 1.0000 - val_loss: 4.3547e-06 - val_accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "5359/5359 [==============================] - 1s 183us/sample - loss: 3.6258e-06 - accuracy: 1.0000 - val_loss: 3.1680e-06 - val_accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "5359/5359 [==============================] - 1s 175us/sample - loss: 2.6422e-06 - accuracy: 1.0000 - val_loss: 2.3030e-06 - val_accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "5359/5359 [==============================] - 1s 187us/sample - loss: 1.9176e-06 - accuracy: 1.0000 - val_loss: 1.6671e-06 - val_accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "5359/5359 [==============================] - 1s 184us/sample - loss: 1.3851e-06 - accuracy: 1.0000 - val_loss: 1.1997e-06 - val_accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "5359/5359 [==============================] - 1s 228us/sample - loss: 9.9206e-07 - accuracy: 1.0000 - val_loss: 8.5408e-07 - val_accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "5359/5359 [==============================] - 1s 208us/sample - loss: 7.0406e-07 - accuracy: 1.0000 - val_loss: 6.0137e-07 - val_accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "5359/5359 [==============================] - 1s 207us/sample - loss: 4.9099e-07 - accuracy: 1.0000 - val_loss: 4.1604e-07 - val_accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "5359/5359 [==============================] - 1s 147us/sample - loss: 3.3552e-07 - accuracy: 1.0000 - val_loss: 2.7884e-07 - val_accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "5359/5359 [==============================] - 1s 143us/sample - loss: 2.2307e-07 - accuracy: 1.0000 - val_loss: 1.8416e-07 - val_accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "5359/5359 [==============================] - 1s 154us/sample - loss: 1.4306e-07 - accuracy: 1.0000 - val_loss: 1.1490e-07 - val_accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "5359/5359 [==============================] - 1s 177us/sample - loss: 8.6710e-08 - accuracy: 1.0000 - val_loss: 6.8294e-08 - val_accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "5359/5359 [==============================] - 1s 171us/sample - loss: 5.1085e-08 - accuracy: 1.0000 - val_loss: 3.8683e-08 - val_accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "5359/5359 [==============================] - 1s 151us/sample - loss: 2.7695e-08 - accuracy: 1.0000 - val_loss: 2.2434e-08 - val_accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "5359/5359 [==============================] - 1s 142us/sample - loss: 1.4859e-08 - accuracy: 1.0000 - val_loss: 1.0653e-08 - val_accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "5359/5359 [==============================] - 1s 134us/sample - loss: 7.4853e-09 - accuracy: 1.0000 - val_loss: 6.0259e-09 - val_accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "5359/5359 [==============================] - 1s 134us/sample - loss: 3.6926e-09 - accuracy: 1.0000 - val_loss: 2.4826e-09 - val_accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "5359/5359 [==============================] - 1s 140us/sample - loss: 1.5571e-09 - accuracy: 1.0000 - val_loss: 1.3993e-09 - val_accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "5359/5359 [==============================] - 1s 133us/sample - loss: 8.7867e-10 - accuracy: 1.0000 - val_loss: 6.9964e-10 - val_accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "5359/5359 [==============================] - 1s 154us/sample - loss: 4.1153e-10 - accuracy: 1.0000 - val_loss: 4.2881e-10 - val_accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "5359/5359 [==============================] - 1s 135us/sample - loss: 3.0030e-10 - accuracy: 1.0000 - val_loss: 4.0624e-10 - val_accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "5359/5359 [==============================] - 1s 133us/sample - loss: 2.0020e-10 - accuracy: 1.0000 - val_loss: 2.4826e-10 - val_accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "5359/5359 [==============================] - 1s 133us/sample - loss: 5.5612e-11 - accuracy: 1.0000 - val_loss: 1.1284e-10 - val_accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "5359/5359 [==============================] - 1s 133us/sample - loss: 2.2245e-11 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "5359/5359 [==============================] - 1s 142us/sample - loss: 2.2245e-11 - accuracy: 1.0000 - val_loss: 4.5138e-11 - val_accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "5359/5359 [==============================] - 1s 137us/sample - loss: 2.2245e-11 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "5359/5359 [==============================] - 1s 133us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.2569e-11 - val_accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "5359/5359 [==============================] - 1s 133us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.5138e-11 - val_accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "5359/5359 [==============================] - 1s 133us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "5359/5359 [==============================] - 1s 135us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "5359/5359 [==============================] - 1s 134us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "5359/5359 [==============================] - 1s 139us/sample - loss: 1.1122e-11 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "5359/5359 [==============================] - 1s 136us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "5359/5359 [==============================] - 1s 183us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/100\n",
      "5359/5359 [==============================] - 1s 141us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "5359/5359 [==============================] - 1s 171us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "5359/5359 [==============================] - 1s 136us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "5359/5359 [==============================] - 1s 145us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "5359/5359 [==============================] - 1s 135us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "5359/5359 [==============================] - 1s 134us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "5359/5359 [==============================] - 1s 133us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "5359/5359 [==============================] - 1s 134us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "5359/5359 [==============================] - 1s 134us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "5359/5359 [==============================] - 1s 134us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "5359/5359 [==============================] - 1s 135us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "5359/5359 [==============================] - 1s 137us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "5359/5359 [==============================] - 1s 134us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "5359/5359 [==============================] - 1s 133us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "5359/5359 [==============================] - 1s 132us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "5359/5359 [==============================] - 1s 133us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "5359/5359 [==============================] - 1s 137us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "5359/5359 [==============================] - 1s 140us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "5359/5359 [==============================] - 1s 133us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "5359/5359 [==============================] - 1s 133us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "5359/5359 [==============================] - 1s 167us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "5359/5359 [==============================] - 1s 158us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "5359/5359 [==============================] - 1s 158us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "5359/5359 [==============================] - 1s 141us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "5359/5359 [==============================] - 1s 136us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "5359/5359 [==============================] - 1s 134us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "5359/5359 [==============================] - 1s 133us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "5359/5359 [==============================] - 1s 133us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "5359/5359 [==============================] - 1s 133us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "5359/5359 [==============================] - 1s 137us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "5359/5359 [==============================] - 1s 137us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "5359/5359 [==============================] - 1s 216us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "5359/5359 [==============================] - 1s 148us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "5359/5359 [==============================] - 1s 155us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "5359/5359 [==============================] - 1s 132us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "5359/5359 [==============================] - 1s 154us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "5359/5359 [==============================] - 1s 197us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "5359/5359 [==============================] - 1s 166us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "5359/5359 [==============================] - 1s 149us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "5359/5359 [==============================] - 1s 167us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "5359/5359 [==============================] - 1s 219us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "5359/5359 [==============================] - 1s 183us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "5359/5359 [==============================] - 1s 180us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "5359/5359 [==============================] - 1s 161us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "5359/5359 [==============================] - 1s 155us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "5359/5359 [==============================] - 1s 164us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "5359/5359 [==============================] - 1s 164us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "5359/5359 [==============================] - 1s 194us/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Fitting the ANN to the Training set\n",
    "model_history=classifier.fit(X_train, y_train,validation_split=0.33, batch_size = 10, nb_epoch = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 3 - Making the predictions and evaluating the model\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 893,    0],\n",
       "       [   0, 1107]], dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the Accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "score=accuracy_score(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
